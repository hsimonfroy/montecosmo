
import os
from itertools import product
from typing import Self
from pathlib import Path

import numpy as np
import matplotlib.pyplot as plt
from jax import numpy as jnp, random as jr, jit, tree, tree_util, flatten_util

from numpyro.diagnostics import print_summary
from getdist import MCSamples

from montecosmo.utils import nvmap
from montecosmo.metrics import multi_ess, multi_gr

from dataclasses import dataclass, fields
from collections import UserDict



@tree_util.register_pytree_node_class
# @partial(tree_util.register_dataclass, data_fields=['data'], meta_fields=['groups']) # JAX >=0.4.27
@dataclass
class Samples(UserDict):
    """
    Global slicing and indexing s[1:3,2]
    Querying with groups, e.g.
    s['abc', 'c', 'd'], s['*~abc'], s['*','~c']
    s[['abc','c'],['d']], s[['*~abc']], s[['*','~c']]
    """
    # see also https://github.com/cosmodesi/cosmoprimo/blob/33011906d323f56c32c77ba034a6679b02f16876/cosmoprimo/emulators/tools/samples.py#L43
    data: dict
    groups: dict = None # dict of list of key

    NoneOrEmpty = object() # a sentinel to return empty dict if key is not found
    def __post_init__(self):
        if isinstance(self.data, Samples):
            otherdict = self.data.asdict()
            self.data = self.data.data # avoid nested Samples
        else:
            otherdict = {}
        selfdict = {field.name: (getattr(self, field.name) or {}).copy() for field in fields(self)} # handle None and shallow copy
        for k in selfdict:
            self.__setattr__(k, otherdict.get(k, {}) | selfdict[k]) # inherit attributes if not updated
        

    ############
    # Querying #
    ############
    def __getitem__(self, key, default_fn=None):
        # Global indexing and slicing
        if self._istreeof(key, (int, slice, type(Ellipsis), np.ndarray, jnp.ndarray)):
            return tree.map(lambda x: x[key], self)

        # Querying with groups
        elif self._istreeof(key, str):
            if isinstance(key, str):
                key = self._parse_key([key])
                if len(key) == 1:
                    return self._get(key[0], default_fn)
                else:
                    return tuple(self._get(k, default_fn) for k in key)

            elif isinstance(key, list): # construct new instance
                if default_fn is self.NoneOrEmpty:
                    data = {k: self.data[k] for k in self._parse_key(key) if k in self.data}
                else:
                    data = {k: self._get(k, default_fn) for k in self._parse_key(key)}
                return type(self)(**self.asdict() | {'data': data})
            
            elif isinstance(key, tuple):
                key = self._parse_key(key)
                if len(key) == 1:
                    return self.__getitem__(key[0], default_fn)
                else:
                    return tuple(self.__getitem__(k, default_fn) for k in key)
    

    def _parse_key(self, key):
        newkey = []
        for k in key:
            if isinstance(k, list):
                newkey += [k] # handle list
            elif isinstance(k, str):
                if k.startswith('*~'): # all except
                    k = k[2:]
                    g = [k] if k in self else self.data.keys() if k=='*' else self.groups.get(k, [k])
                    # NOTE: parse self first for compatibility with dict, update, etc.
                    newkey += list(self.data.keys() - set(g))
                elif k.startswith('~'): # except
                    k = k[1:]
                    g = [k] if k in self else self.data.keys() if k=='*' else self.groups.get(k, [k])
                    for kk in g:
                        newkey.remove(kk) if kk in newkey else None
                else:
                    g = [k] if k in self else self.data.keys() if k=='*' else self.groups.get(k, [k])
                    newkey += list(g)
            else:
                raise KeyError(k)
        return newkey
    
    
    def _istreeof(self, obj, type):
        return tree.all(tree.map(lambda x: isinstance(x, type), obj))
    
    def _get(self, key, default_fn=None):
        # Rewrite dict get method to raise KeyError by default.
        if key in self.data:
            return self.data[key]
        elif default_fn is None:
            raise KeyError(key)
        elif default_fn is self.NoneOrEmpty:
            # NOTE: NoneOrEmpty is a sentinel that behaves as lambda k: None 
            # except when ask for subdict where it will return empty dict for keys not found.
            return None
        else:
            return default_fn(key)

    def get(self, key, default_fn=NoneOrEmpty):
        """
        If key is not found, get will by default return None when asked for value,
        and empty dict when asked for subdict. To get subdict with None value, use `default_fn=lambda k:None`.
        """
        return self.__getitem__(key, default_fn)


    #########
    # Utils #
    #########
    def asdict(self):
        # NOTE: dataclasses.asdict makes deepcopy, cf. https://github.com/python/cpython/issues/88071
        # here, attributes are only shallow copied
        return {field.name: getattr(self, field.name).copy() for field in fields(self)}

    def __copy__(self) -> Self: 
        # NOTE: UserDict copy() would not copy other attributes than data
        return type(self)(**self.asdict())
                 
    # NOTE: no need with register_dataclass JAX >=0.4.27
    def tree_flatten(self):
        return (self.data,), (self.groups,)
    
    @classmethod
    # NOTE: no need with register_dataclass JAX >=0.4.27
    def tree_unflatten(cls, aux, data):
        return cls(*data, *aux)
    

    ##############
    # Properties #
    ##############
    @property
    def shape(self) -> Self:
        return tree.map(jnp.shape, self.data)
    
    @property
    def ndim(self) -> Self:
        return tree.map(jnp.ndim, self.data)
    
    @property
    def dtype(self) -> Self:
        return tree.map(jnp.dtype, self.data)
    
    @property
    def size(self) -> Self:
        return tree.map(jnp.size, self.data)
    

    ##############
    # Operations #
    ##############
    def __or__(self, other) -> Self:
        newdict = self.asdict()
        if isinstance(other, Samples):
            otherdict = other.asdict()
            for k in otherdict:
                if k in newdict:
                    newdict[k] = newdict[k] | otherdict[k]
                else:
                    return NotImplemented
        elif isinstance(other, UserDict):
            newdict |= {'data': self.data | other.data}
        elif isinstance(other, dict):
            newdict |= {'data': self.data | other}
        else:
            return NotImplemented
        return type(self)(**newdict)
    
    def __ror__(self, other) -> Self:
        newdict = self.asdict()
        if isinstance(other, Samples):
            otherdict = other.asdict()
            for k in otherdict:
                if k in newdict:
                    newdict[k] = otherdict[k] | newdict[k]
                else:
                    return NotImplemented
        elif isinstance(other, UserDict):
            newdict |= {'data': other.data | self.data}
        elif isinstance(other, dict):
            newdict |= {'data': other | self.data}
        else:
            return NotImplemented
        return type(self)(**newdict)

    def __ior__(self, other) -> Self: 
        # NOTE: inplace or, so dict |= UserDict remains a dict, contrary to dict | UserDict
        if isinstance(other, Samples):
            otherdict = other.asdict()
            selfdict = self.asdict()
            for k in selfdict:
                self.__setattr__(k, selfdict[k] | otherdict.get(k, {}) )
            return self
        else:
            return super().__ior__(other)
        

    ##############
    # Transforms #
    ##############
    def prune(self) -> Self:
        """
        Remove keys in groups that are not in data.
        """
        new = self.copy()
        new.groups = {g: [k for k in gl if k in new.data] for g, gl in new.groups.items()}
        return new
    
    def concat(self, *others, axis=0) -> Self:
        return tree.map(lambda x, *y: jnp.concatenate((x, *y), axis=axis), self, *others)

    def stackby(self, names:str|list=None, remove=True, axis=-1) -> Self:
        """
        Stack variables by groups, optionally removing unstacked variables.

        names can be variable names (no stacking) or group names.
        If names is None, all groups are stacked.
        """
        if names is None:
            names = list(self.groups)
        elif isinstance(names, str):
            names = [names]

        new = self.copy()
        for k in names:
            if k not in self: # if name is a variable, do nothing
                if len(self.groups[k]) == 1:
                    new.data[k] = self[k]
                else:
                    new.data[k] = jnp.stack(self[k], axis=axis)

                # Remove unstacked variables
                if remove:
                    for k in self.groups[k]:
                        new.data.pop(k)
        return new










@tree_util.register_pytree_node_class
@dataclass
class Chains(Samples):
    labels: dict = None
        
    # NOTE: no need with register_dataclass JAX >=0.4.27
    def tree_flatten(self):
        return (self.data,), (self.groups, self.labels)


    @classmethod
    def load_runs(cls, path:str|Path, start:int, end:int, transforms=None, groups=None, labels=None, batch_ndim=2) -> Self:
        """
        Load and append runs saved in different files with names of the form `run_{i}.npz`.

        Both runs `start` and `end` are included.
        Runs are concatenated along last batch dimension.
        """
        path = Path(path)
        print(f"Loading: {path}, from run {start} to run {end} (included)")
        for i_run in range(start, end + 1):
            run_path = path / f"run_{i_run}.npz"
            if not os.path.exists(run_path):
                if i_run == start:
                    raise FileNotFoundError(f"File {run_path} does not exist")
                else:
                    print(f"File {run_path} does not exist, stopping at run {i_run-1}")
                    end = i_run - 1
                    break
            
        if transforms is None:
            transforms = []
        transforms = np.atleast_1d(transforms)
        conc_axis = max(batch_ndim-1, 0)

        @jit
        def transform(samples):
            for trans in transforms:
                samples = trans(samples)
            return samples

        for i_run in range(start, end + 1):
            # Load
            run_path = path / f"run_{i_run}.npz"
            part = dict(jnp.load(run_path)) # better than pickle for dict of array-like
            part = cls(part, groups=groups, labels=labels)
            part = transform(part)

            # Init or append samples
            if batch_ndim == 0:
                part = tree.map(lambda x: x[None], part)

            if i_run == start:
                samples = part
            else:
                samples = samples.concat(part, axis=conc_axis)
                del part  

        return samples

    ######################
    # General Transforms #
    ######################
    def splitrans(self, transform, n, axis=1) -> Self:
        """
        Apply transform on n splits along given axis.
        Stack n values along first axis.
        """
        assert n <= np.shape(self[next(iter(self))])[axis], "n should be less (<=) than the length of given axis."
        out = tree.map(lambda x: jnp.array_split(x, n, axis), self)
        out = transform(out)
        
        for k in out:
            out[k] = jnp.stack(out[k])
        return out

    def cumtrans(self, transform, n, axis=1) -> Self:
        """
        Apply transform on n cumulative slices along given axis.
        Stack n values along first axis.
        """
        length = np.shape(self[next(iter(self))])[axis]
        ends = np.rint(np.arange(1,n+1) / n * length).astype(int)
        out = tree.map(lambda x: [], self)
        for end in ends:
            part = tree.map(lambda x: x[axis*(slice(None),) + (slice(None,end),)], self)
            part = transform(part)
            for k in self:
                out[k].append(part[k])

        for k in self:
            out[k] = jnp.stack(out[k])
        return out
    
    def choice(self, n, names:str|list=None, seed=42, batch_ndim=2, replace=False) -> Self:
        """
        Select a random subsample of size n along given axis for variables selected by names.
        names can be variable names or group names.
        """
        if names is None:
            names = list(self)
        else:
            names = np.atleast_1d(names)

        if isinstance(seed, int):
            seed = jr.key(seed)
        fn = lambda x: jr.choice(seed, x.reshape(-1), shape=(n,), replace=replace)
        fn = nvmap(fn, batch_ndim)

        new = self.copy()
        for k in names:
            new |= tree.map(fn, new.get([k]))
        return new

    def thin(self, thinning=None, moment=None, axis:int=1) -> Self:
        # All item shapes should match on given axis so take the first item shape
        length = jnp.shape(next(iter(self.values())))[axis]
        if thinning is None:
            n_split = 1
        else:
            n_split = max(np.rint(length / thinning), 1)
        
        if moment is None:
            fn = lambda c: Chains.last(c, axis=axis)
        else:
            fn = lambda c: Chains.moment(c, m=moment, axis=axis)
        out = self.splitrans(fn, n_split, axis=axis)
        return tree.map(lambda x: jnp.moveaxis(x, 0, axis), out)
    
    def flatten(self, batch_ndim=2) -> Self:
        """
        Flatten all non-batch dimensions, creating new keys.
        Update groups and labels accordingly.
        """
        # Flatten data
        data = {}
        labels = {}
        substitute = {}

        for k, v in self.data.items():
            shape = jnp.shape(v)[batch_ndim:]
            if len(shape) == 0:
                # Get data and labels
                data[k] = v
                if k in self.labels:
                    labels[k] = self.labels[k]
            else:
                substitute[k] = []
                for ids in product(*map(range, shape)):
                    sufx = "[{}]".format(",".join(map(str, ids)))
                    slices = batch_ndim * (slice(None),)
                    for id in ids:
                        slices += (id,)
                    
                    # Update data and labels
                    data[k + sufx] = v[slices]
                    if k in self.labels:
                        labels[k + sufx] = self.labels[k] + sufx

                    # Register substitution to update groups
                    substitute[k].append(k + sufx)
        
        # Update groups
        groups = {}
        for g, gl in self.groups.items():
            groups[g] = [] # make a new list to not overwrite shallow copied groups
            for k in gl:
                if k in substitute:
                    groups[g] += substitute[k]
                else:
                    groups[g].append(k)
        return Chains(data, groups=groups, labels=labels)
    
    def ravel(self, batch_ndim=2):
        """
        Ravel chains into an array with `batch_ndim` leading dimensions.
        Return both raveled array and unravel function.
        """
        unravel = nvmap(flatten_util.ravel_pytree(tree.map(lambda x: x[(0,)*batch_ndim], self))[1], batch_ndim)
        raveled = nvmap(lambda x: flatten_util.ravel_pytree(x)[0], batch_ndim)(self)
        return raveled, unravel




    #####################
    # Metric Transforms #
    #####################
    def metric(self, fn, *others, axis=None) -> Self:
        """
        Tree map chains but treat 'n_evals' item separately by summing it along axis.
        `self` and `others` should have matching keys, except possibly 'n_evals'.
        """
        name = "n_evals"
        infos, rest = self.get(([name], ['*~'+name]))
        infos = tree.map(lambda x: jnp.sum(x, axis), infos)
        others_new = (other[['*~'+name]] for other in others)

        return infos | tree.map(fn, rest, *others_new)
    
    def last(self, axis=1) -> Self:
        return self.metric(lambda x: jnp.take(x, -1, axis), axis=axis)
    
    def moment(self, m:int|list=(0,1,2), axis=1) -> Self:
        if isinstance(m, int):
            fn = lambda x: jnp.sum(x**m, axis)
        else:
            m = jnp.asarray(m)
            fn = lambda x: jnp.sum(x[...,None]**m, axis)
        return self.metric(fn, axis=axis)
    
    def center_moment(self, axis=-1) -> Self:
        def center(moments, axis):
            moments = jnp.moveaxis(moments, axis, 0)
            count = moments[0]
            mean = moments[1] / count
            std = (moments[2] / count - mean**2)**.5
            return jnp.stack((mean, std), axis)
        
        return self.metric(lambda x: center(x, axis), axis=())
    
    def cmoment(self, axis=1) -> Self:
        fn = lambda x: jnp.stack((x.mean(axis), x.std(axis)), -1)
        return self.metric(fn, axis=axis)

    # def mse(self, truth, axis=0) -> Self:
    #     return self.metric(lambda x, y: jnp.mean((x-y)**2, axis), truth)
    
    def mse_cmoment(self, true_cmom, axis=None) -> Self:
        cmom = self.cmoment(axis=1)
        true_cmom = Chains(true_cmom, self.groups, self.labels) # cast into Chains

        def mse_mom(est, true, axis):
            n_chains = est.shape[0]
            est = jnp.moveaxis(est, -1, 0)
            true = jnp.moveaxis(true, -1, 0)
            sqrerr_mean = ((est[0] - true[0]) / true[1])**2 / n_chains
            sqrerr_std = 2 * ((est[1] - true[1]) / true[1])**2 / n_chains
            # NOTE: such square errors are asymptotically N(0, 1 / n_eff)^2 = chi^2(1) / n_eff
            return jnp.stack((sqrerr_mean.mean(axis), sqrerr_std.mean(axis)))
            # NOTE: asymptotically chi^2(n_c * n_d) / (n_c * n_d * n_eff)

        return cmom.metric(lambda x, y: mse_mom(x, y, axis), true_cmom)

    def eval_times_mse(self, truth, axis=None) -> Self:
        mse_mom = self.mse_cmoment(truth, axis=axis)
        name = "n_evals" 
        infos, rest = mse_mom[[name], ['*~'+name]]
        return infos | tree.map(lambda x: infos[name] * x, rest)

    def multi_ess(self, axis=None) -> Self:
        return self.metric(lambda x: multi_ess(x, axis=axis))
    
    def eval_per_ess(self, axis=None) -> Self:
        ess = self.multi_ess(axis=axis)
        name = "n_evals" 
        infos, rest = ess[[name], ['*~'+name]]
        return infos | tree.map(lambda x: infos[name] / x, rest)


    ############
    # Plotting #
    ############
    def to_getdist(self, label=None):
        samples, names, labels = [], [], []
        for k, v in self.data.items():
            # Flatten all chains
            samples.append(v.reshape(-1))
            names.append(k)
            labels.append(self.labels.get(k, None))
        return MCSamples(samples=samples, names=names, labels=labels, label=label)
    
    def print_summary(self, group_by_chain=True):
        print_summary(self.data, group_by_chain=group_by_chain)


    def plot(self, names:str|list=None, batch_ndim=2, grid=True, log=False):
        """
        Plot chains. names can be variable names or group names.
        """
        if names is None:
            names = list(self)
        else:
            names = list(np.atleast_1d(names))
        
        # Concatenate extra dims or expand missing dims
        n_conc = max(batch_ndim-2, 0)
        n_exp = max(2-batch_ndim, 0)
        def conc_exp_fn(v):
            for _ in range(n_conc):
                v = jnp.concatenate(v)
            return jnp.expand_dims(v, axis=range(n_exp))
        conc = tree.map(conc_exp_fn, self[names])

        # All item shapes should match on the first batch_ndim dimensions,
        # so take the first item shape
        n_chains = jnp.shape(next(iter(conc.values())))[0]

        fig = plt.gcf()
        subfigs = fig.subfigures(len(names), 1)
        subfigs = np.atleast_1d(subfigs)
        for subfig, name in zip(subfigs, names):

            subfig.suptitle(f"{name}")
            axs = subfig.subplots(1, n_chains, sharey='row')
            axs = np.atleast_1d(axs)
            subfig.subplots_adjust(wspace=0)

            for i_n, (k, v) in enumerate(conc[[name]].items()):
                for i_c, ax in enumerate(axs):
                    label = conc.labels.get(k)
                    ax.plot(v[i_c], label=k if label is None else '$'+label+'$')
                    if log: 
                        ax.set_yscale('log')
                    ax.grid(grid)

                    xlab = ax.get_xticklabels()
                    if xlab and i_n==0:
                        plt.setp(xlab[:2], visible=False)

                ax.legend()




    