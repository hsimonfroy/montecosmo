{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference\n",
    "Infer from a cosmological model via MCMC samplers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started running on feynmangpu04 at 2024-12-12T09:48:28+01:00\n",
      "Submitted from host feynmannode11.cluster.local to node(s) feynmangpu04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/feynman/work/dphp/hs276503/envs/montenvtest3/lib/python3.12/pty.py:95: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "!echo \"Started running on $(hostname -s) at $(date -Is)\"\n",
    "!echo \"Submitted from host $SLURM_SUBMIT_HOST to node(s) $SLURM_JOB_NODELIST\"\n",
    "import os; os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION']='.50' # NOTE: jax preallocates GPU (default 75%)\n",
    "import jax; print(jax.default_backend())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from jax import numpy as jnp, random as jr, jit, vmap, grad, debug, tree\n",
    "\n",
    "from functools import partial\n",
    "from getdist import plots\n",
    "from numpyro import infer\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from montecosmo.model import FieldLevelModel, default_config\n",
    "from montecosmo.utils import pdump, pload\n",
    "from montecosmo.mcbench import sample_and_save\n",
    "\n",
    "# import mlflow\n",
    "# mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8081\")\n",
    "# mlflow.set_experiment(\"infer\")\n",
    "# !jupyter nbconvert --to script ./src/montecosmo/tests/infer_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config and fiduc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading truth from /feynman/home/dphp/hs276503/scratch/pickles/m64_b640.0_al0.1_ao0.5_lo1_pc3_obmesh/\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "save_dir = os.path.expanduser(\"~/scratch/pickles/\")\n",
    "config = {\n",
    "          # Mesh and box parameters\n",
    "          'mesh_shape':3 * (64,), # int\n",
    "          'box_shape':3 * (640.,), # in Mpc/h (aim for cell lengths between 1 and 10 Mpc/h)\n",
    "          # LSS formation\n",
    "          'a_lpt':0.1,\n",
    "          'lpt_order':1,\n",
    "          'precond':3,\n",
    "          }\n",
    "\n",
    "# Load and save model\n",
    "model = FieldLevelModel(**default_config | config)\n",
    "def get_save_dir(**kwargs):\n",
    "    dir = os.path.expanduser(\"~/scratch/pickles/\")\n",
    "    # dir = os.path.expanduser(\"/lustre/fsn1/projects/rech/fvg/uvs19wt/pickles/\")\n",
    "    dir += f\"m{kwargs['mesh_shape'][0]:d}_b{kwargs['box_shape'][0]:.1f}\"\n",
    "    dir += f\"_al{kwargs['a_lpt']:.1f}_ao{kwargs['a_obs']:.1f}_lo{kwargs['lpt_order']:d}_pc{kwargs['precond']:d}_ob{kwargs['obs']}/\"\n",
    "    return dir\n",
    "save_dir = get_save_dir(**model.__dict__)\n",
    "# print(model)\n",
    "# model.render(0,1)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    # Predict and save fiducial\n",
    "    truth = {'Omega_m': 0.31, \n",
    "            'sigma8': 0.81, \n",
    "            'b1': 1., \n",
    "            'b2':0., \n",
    "            'bs2':0., \n",
    "            'bn2': 0.}\n",
    "\n",
    "    model.reset()\n",
    "    truth = model.predict(samples=truth, hide_base=False, frombase=True)\n",
    "    \n",
    "    print(f\"Saving model and truth at {save_dir}\")\n",
    "    os.mkdir(save_dir)\n",
    "    model.save(save_dir)    \n",
    "    pdump(truth, save_dir + \"truth.p\")\n",
    "else:\n",
    "    print(f\"Loading truth from {save_dir}\")\n",
    "    truth = pload(save_dir + \"truth.p\")\n",
    "\n",
    "model.condition({'obs': truth['obs']})\n",
    "if model.precond==3:\n",
    "    model.obs_meshk = truth['obs']\n",
    "model.block()\n",
    "# model.render(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUTS, HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = \"NUTS\"\n",
    "n_samples, max_tree_depth, n_runs, n_chains = 64, 10, 10, 8\n",
    "save_path = save_dir + f\"s{sampler}_nc{n_chains:d}_ns{n_samples:d}\"\n",
    "\n",
    "\n",
    "nuts_kernel = infer.NUTS(\n",
    "    model=model.model,\n",
    "    # init_strategy=numpyro.infer.init_to_value(values=fiduc_params)\n",
    "    adapt_mass_matrix=True,\n",
    "    step_size=1e-3, \n",
    "    adapt_step_size=True,\n",
    "    max_tree_depth=max_tree_depth,\n",
    "    target_accept_prob=0.65,)\n",
    "\n",
    "hmc_kernel = infer.HMC(\n",
    "    model=model.model,\n",
    "    # init_strategy=numpyro.infer.init_to_value(values=fiduc_params),\n",
    "    adapt_mass_matrix=True,\n",
    "    step_size=1e-3, \n",
    "    adapt_step_size=True,\n",
    "    # Rule of thumb (2**max_tree_depth-1)*step_size_NUTS/(2 to 4), compare with default 2pi.\n",
    "    trajectory_length= 1023 * 1e-3 / 4, \n",
    "    target_accept_prob=0.65,)\n",
    "\n",
    "mcmc = infer.MCMC(\n",
    "    sampler=nuts_kernel,\n",
    "    num_warmup=n_samples,\n",
    "    num_samples=n_samples, # for each run\n",
    "    num_chains=n_chains,\n",
    "    chain_method=\"vectorized\",\n",
    "    progress_bar=True,)\n",
    "\n",
    "\n",
    "continue_run = False\n",
    "if continue_run:\n",
    "    mcmc.num_warmup = 0\n",
    "    last_state = pload(save_path + \"_last_state.p\")\n",
    "    mcmc.post_warmup_state = last_state\n",
    "\n",
    "# print(\"mean_acc_prob:\", last_state.mean_accept_prob, \"\\nss:\", last_state.adapt_state.step_size)\n",
    "# invmm = list(last_state.adapt_state.inverse_mass_matrix.values())[0][0]\n",
    "# invmm.min(),invmm.max(),invmm.mean(),invmm.std()\n",
    "\n",
    "# Init params\n",
    "init_model = model.copy()\n",
    "init_model.partial(temp=1e-2)\n",
    "init_params_ = init_model.predict(samples=n_chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0/10 (warmup)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/feynman/work/dphp/hs276503/envs/montenvtest/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/feynman/work/dphp/hs276503/envs/montenvtest/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/feynman/work/dphp/hs276503/envs/montenvtest/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/feynman/work/dphp/hs276503/envs/montenvtest/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/feynman/work/dphp/hs276503/envs/montenvtest/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/feynman/work/dphp/hs276503/envs/montenvtest/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/feynman/work/dphp/hs276503/envs/montenvtest/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/feynman/work/dphp/hs276503/envs/montenvtest/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/feynman/work/dphp/hs276503/envs/montenvtest/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/feynman/work/dphp/hs276503/envs/montenvtest/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "  0%|          | 0/64 [00:00<?, ?it/s]/feynman/work/dphp/hs276503/envs/montenvtest/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/feynman/work/dphp/hs276503/envs/montenvtest/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/feynman/work/dphp/hs276503/envs/montenvtest/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "warmup:   2%|‚ñè         | 1/64 [05:29<5:46:28, 329.98s/it]"
     ]
    }
   ],
   "source": [
    "# mlflow.log_metric('halt',0) # 31.46s/it 4chains, 37.59s/it 8chains\n",
    "mcmc_runned = sample_and_save(mcmc, n_runs, save_path, extra_fields=['num_steps'], init_params=init_params_)\n",
    "# mlflow.log_metric('halt',1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
